{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.options.mode.chained_assignment = None # Turn off some annoying pandas warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setting seed for reproducible results\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GgrCAtvgf2L",
        "outputId": "198a7aa3-4e2d-47b7-aace-4a4e55971978"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\super\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: The input object of type 'PngImageFile' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'PngImageFile', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "c:\\Users\\super\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images and labels saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the folder paths\n",
        "folder_path1 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Karim Abdelaziz\\Training'\n",
        "folder_path2 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Karim Abdelaziz\\Testing'\n",
        "folder_path3 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Karim Abdelaziz\\Validation'\n",
        "\n",
        "folder_path4 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Hend Sabry\\Training'\n",
        "folder_path5 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Hend Sabry\\Testing'\n",
        "folder_path6 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Hend Sabry\\Testing'\n",
        "\n",
        "folder_path7 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Hany Ramzy\\Training'\n",
        "folder_path8 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Hany Ramzy\\Testing'\n",
        "folder_path9 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Actors DataSet predifined\\Actors DataSet\\Hany Ramzy\\Validation'\n",
        "\n",
        "# Function to read images from a folder and resize them\n",
        "def read_images_from_folder(folder_path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "                # Open image using PIL\n",
        "                img = Image.open(img_path)\n",
        "\n",
        "                # Convert to RGB mode if not already in that mode\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "        except Exception as e:\n",
        "                print(f\"Error loading image {image_path}: {e}\")\n",
        "\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Paths to your image folders and labels\n",
        "folder_paths = [folder_path1, folder_path2, folder_path3, folder_path4, folder_path5, folder_path6, folder_path7, folder_path8, folder_path9]\n",
        "labels = [\"Karim AbdelAziz\", \"Karim AbdelAziz\", \"Karim AbdelAziz\", \"Hend Sabry\", \"Hend Sabry\", \"Hend Sabry\", \"Hany Ramzy\", \"Hany Ramzy\", \"Hany Ramzy\"]  # Example labels for each folder\n",
        "\n",
        "# Initialize empty lists to store images and corresponding labels\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "# Read images from each folder and store them in all_images list\n",
        "# Also, store corresponding labels in all_labels list\n",
        "for folder_path, label in zip(folder_paths, labels):\n",
        "    images, label_list = read_images_from_folder(folder_path, label)\n",
        "    all_images.extend(images)\n",
        "    all_labels.extend(label_list)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Save the images and labels arrays to numpy files\n",
        "np.save(\"images.npy\", all_images)\n",
        "np.save(\"labels.npy\", all_labels)\n",
        "\n",
        "print(\"Images and labels saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x28CC290AB70>\n",
            "Hany Ramzy\n"
          ]
        }
      ],
      "source": [
        "print(all_images[5000])\n",
        "print(all_labels[5000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"image\": all_images, \"label\": all_labels})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Karim AbdelAziz    2390\n",
              "Hany Ramzy         1574\n",
              "Hend Sabry          826\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique labels in the DataFrame:\n",
            "['Karim AbdelAziz' 'Hend Sabry' 'Hany Ramzy']\n"
          ]
        }
      ],
      "source": [
        "unique_labels = df['label'].unique()\n",
        "print(\"Unique labels in the DataFrame:\")\n",
        "print(unique_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label2id mapping:\n",
            "{'Karim AbdelAziz': 0, 'Hend Sabry': 1, 'Hany Ramzy': 2}\n",
            "id2label mapping:\n",
            "{0: 'Karim AbdelAziz', 1: 'Hend Sabry', 2: 'Hany Ramzy'}\n"
          ]
        }
      ],
      "source": [
        "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "print(\"label2id mapping:\")\n",
        "print(label2id)\n",
        "print(\"id2label mapping:\")\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map labels to ids\n",
        "\n",
        "df_train['class'] = df_train['label'].map(label2id)\n",
        "df_test['class'] = df_test['label'].map(label2id)\n",
        "\n",
        "\n",
        "df_train = df_train.sample(frac=1, random_state=SEED)\n",
        "df_test = df_test.sample(frac=1, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fix_image(img):\n",
        "  \n",
        "  rgb_img = img.convert(\"RGB\")\n",
        "\n",
        "  return np.array(rgb_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images = np.array([fix_image(img) for img in df_train['image'].to_list()])\n",
        "test_images = np.array([fix_image(img) for img in df_test['image'].to_list()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = np.array([label for label in df_train['class'].to_list()])\n",
        "test_labels = np.array([label for label in df_test['class'].to_list()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = to_categorical(train_labels, 3)\n",
        "test_labels = to_categorical(test_labels, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4790, 512, 512, 3), (4790, 3), (1198, 512, 512, 3), (1198, 3))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('train_images.npy', train_images)\n",
        "np.save('test_images.npy', test_images)\n",
        "np.save('train_labels.npy', train_labels)\n",
        "np.save('test_labels.npy', test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images = np.load('train_images.npy')\n",
        "test_images = np.load('test_images.npy')\n",
        "train_labels = np.load('train_labels.npy')\n",
        "test_labels = np.load('test_labels.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_labels = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WXpTaE2mmyJi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "120/120 [==============================] - 439s 4s/step - loss: 1.0490 - accuracy: 0.5598 - val_loss: 0.6282 - val_accuracy: 0.7296\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 440s 4s/step - loss: 0.6197 - accuracy: 0.7343 - val_loss: 0.3581 - val_accuracy: 0.8800\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 437s 4s/step - loss: 0.2859 - accuracy: 0.8972 - val_loss: 0.2574 - val_accuracy: 0.9081\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 436s 4s/step - loss: 0.2008 - accuracy: 0.9175 - val_loss: 0.1910 - val_accuracy: 0.9186\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 435s 4s/step - loss: 0.2016 - accuracy: 0.9165 - val_loss: 0.2538 - val_accuracy: 0.9050\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = 3\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Feature Extraction Stage\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", activation='relu', input_shape=(512, 512, 3))) # Number of parameters = 8 x (3 x 3) x 3 + 8 = 224\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", activation='relu', input_shape=(512, 512, 3))) # Number of parameters = 8 x (3 x 3) x 3 + 8 = 224\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", activation='relu')) # Number of parameters = 16 x (5 x 5) x 8 + 16 = 3216\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding=\"valid\", activation='relu', input_shape=(512, 512, 3))) # Number of parameters = 8 x (3 x 3) x 3 + 8 = 224\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(7, 7), strides=(1, 1), padding=\"valid\", activation='relu')) # Number of parameters = 32 x (3 x 3) x 16 + 32 = 4640\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Classification Stage\n",
        "model.add(Dense(units=128, activation='relu')) # Should be sigmoid but sigmoid has decresed the accuracy thats why we used relu\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_labels, activation='softmax')) # Number of parameters = 256 x 6 + 6 = 15426 = 1542\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x=train_images, y=train_labels, validation_split=0.2, batch_size=32, epochs=5, shuffle=True)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('trained_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 30s 780ms/step\n"
          ]
        }
      ],
      "source": [
        "test_new_labels = model.predict(test_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 90.73%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Convert one-hot encoded test_labels back to categorical labels\n",
        "test_labels_categorical = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test_new_labels to categorical labels\n",
        "test_new_labels_categorical = np.argmax(test_new_labels, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels_categorical, test_new_labels_categorical)\n",
        "\n",
        "# Print accuracy\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
