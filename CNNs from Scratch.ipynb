{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV7Hs14kPPAl",
        "outputId": "d6fc8db8-d875-4373-fdd6-84260b817395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images and labels saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Local paths to your image folders\n",
        "folder_path1 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Our Dataset\\Our Dataset\\Karim Abdelaziz Cropped 2\\Karim Training'\n",
        "folder_path2 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Our Dataset\\Our Dataset\\Hend Sabry Cropped\\Hend Training'\n",
        "folder_path3 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Our Dataset\\Our Dataset\\Hany Ramzy Cropped\\Hany Training'\n",
        "\n",
        "# Function to read images from a folder and resize them\n",
        "def read_images_from_folder(folder_path, label, image_size=(512, 512)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is not None:\n",
        "            # Resize image to 512x512x3\n",
        "            img = cv2.resize(img, image_size)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Paths to your image folders and labels\n",
        "folder_paths = [folder_path1, folder_path2, folder_path3]\n",
        "labels = [\"Karim\", \"Hend\", \"Hany\"]  # Example labels for each folder\n",
        "\n",
        "# Initialize empty lists to store images and corresponding labels\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "\n",
        "for folder_path, label in zip(folder_paths, labels):\n",
        "    images, label_list = read_images_from_folder(folder_path, label)\n",
        "    all_images.extend(images)\n",
        "    all_labels.extend(label_list)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Save the images and labels arrays to numpy files\n",
        "np.save(\"images.npy\", all_images)\n",
        "np.save(\"labels.npy\", all_labels)\n",
        "\n",
        "print(\"Images and labels saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8XGhpG_PO9e",
        "outputId": "4ed95128-f8d6-421c-ab04-65d7378a1912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[ 46  84 126]\n",
            "  [ 46  84 126]\n",
            "  [ 46  84 126]\n",
            "  ...\n",
            "  [142 168 182]\n",
            "  [145 171 185]\n",
            "  [146 172 186]]\n",
            "\n",
            " [[ 46  84 126]\n",
            "  [ 46  84 126]\n",
            "  [ 46  84 126]\n",
            "  ...\n",
            "  [142 168 182]\n",
            "  [145 171 185]\n",
            "  [146 172 186]]\n",
            "\n",
            " [[ 46  84 126]\n",
            "  [ 46  84 126]\n",
            "  [ 46  84 126]\n",
            "  ...\n",
            "  [142 168 182]\n",
            "  [144 170 184]\n",
            "  [145 171 185]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[105 120 123]\n",
            "  [105 120 123]\n",
            "  [106 121 124]\n",
            "  ...\n",
            "  [ 67  84  93]\n",
            "  [ 66  83  92]\n",
            "  [ 66  83  92]]\n",
            "\n",
            " [[105 120 123]\n",
            "  [105 120 123]\n",
            "  [106 121 124]\n",
            "  ...\n",
            "  [ 67  84  93]\n",
            "  [ 67  84  93]\n",
            "  [ 67  84  93]]\n",
            "\n",
            " [[105 120 123]\n",
            "  [105 120 123]\n",
            "  [106 121 124]\n",
            "  ...\n",
            "  [ 68  85  94]\n",
            "  [ 67  84  93]\n",
            "  [ 67  84  93]]]\n",
            "Hany\n"
          ]
        }
      ],
      "source": [
        "print(all_images[800])\n",
        "print(all_labels[800])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snGJen6fT8OF"
      },
      "source": [
        "# Convo Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n3bkGFVXPO6H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class ConvLayer:\n",
        "    def __init__(self, num_filters, filter_size, filter_weights=None):\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size\n",
        "\n",
        "        if filter_weights is None:\n",
        "            # Initialize random filter weights\n",
        "            self.filters = np.random.randn(num_filters, *filter_size) / (filter_size[0] * filter_size[1])\n",
        "        else:\n",
        "            # Use predefined filter weights\n",
        "            \n",
        "            self.filters = filter_weights\n",
        "\n",
        "    @classmethod\n",
        "    def from_filters(cls, filters):\n",
        "        \"\"\"\n",
        "        Initialize the ConvLayer with predefined filter weights.\n",
        "\n",
        "        :param filters: Predefined filters (num_filters, height, width, channels).\n",
        "        \"\"\"\n",
        "        num_filters, height, width, channels = filters.shape\n",
        "        conv_layer = cls(num_filters, (height, width, channels))\n",
        "        conv_layer.filters = filters\n",
        "        return conv_layer\n",
        "    def iterate_filters(self, input_data):\n",
        "        \"\"\"\n",
        "        Iterate over filters and apply them to the input data.\n",
        "\n",
        "        :param input_data: Input data (batch_size, height, width, channels).\n",
        "        :return: Convolved output.\n",
        "        \"\"\"\n",
        "        batch_size, height, width, channels = input_data.shape\n",
        "\n",
        "        # Iterate over each filter\n",
        "        for f in range(self.num_filters):\n",
        "            filter_height, filter_width, filter_channels = self.filters[f].shape\n",
        "             # Initialize output array\n",
        "            conv_output = np.zeros((batch_size, height - filter_height + 1, width - filter_width + 1, self.num_filters))\n",
        "            for h in range(height - filter_height + 1):\n",
        "                for w in range(width - filter_width + 1):\n",
        "                    # Extract patch from input data\n",
        "                    patch = input_data[:, h:h + filter_height, w:w + filter_width, :filter_channels]\n",
        "\n",
        "                    # Apply filter\n",
        "                    conv_output[:, h, w, f] = np.sum(patch * self.filters[f], axis=(1, 2, 3))\n",
        "\n",
        "        return conv_output\n",
        "    \n",
        "\n",
        "    def forward(self, input_data):\n",
        "        \"\"\"\n",
        "        Perform forward pass for convolutional layer.\n",
        "\n",
        "        :param input_data: Input data (batch_size, height, width, channels).\n",
        "        :return: Output data after convolution.\n",
        "        \"\"\"\n",
        "        return self.iterate_filters(input_data)\n",
        "\n",
        "\n",
        "# Predefined filters\n",
        "filters = np.array([\n",
        "    [[[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
        "     [[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
        "     [[1, 1, 1], [1, 1, 1], [1, 1, 1]]],  \n",
        "\n",
        "    [[[0, 0, 0], [0, 1, 0], [0, 0, 0]],\n",
        "     [[0, 0, 0], [0, 1, 0], [0, 0, 0]],\n",
        "     [[0, 0, 0], [0, 1, 0], [0, 0, 0]]],  \n",
        "\n",
        "    [[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],\n",
        "     [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],\n",
        "     [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]],  \n",
        "\n",
        "    [[[-1, -2, -1], [0, 0, 0], [1, 2, 1]],\n",
        "     [[-1, -2, -1], [0, 0, 0], [1, 2, 1]],\n",
        "     [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]], \n",
        "\n",
        "    [[[0, -1, 0], [-1, 5, -1], [0, -1, 0]],\n",
        "     [[0, -1, 0], [-1, 5, -1], [0, -1, 0]],\n",
        "     [[0, -1, 0], [-1, 5, -1], [0, -1, 0]]]   \n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTyRpiiT0M2"
      },
      "source": [
        "# Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-6Ed67qOTzha"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class PoolingLayer:\n",
        "    def __init__(self, pool_size=(2, 2), pool_type='MAX'):\n",
        "        \"\"\"\n",
        "        Initialize the PoolingLayer with the given pool size and type.\n",
        "\n",
        "        :param pool_size: Size of the pooling filter (height, width).\n",
        "        :param pool_type: Pooling type ('MAX' or 'AVG').\n",
        "        \"\"\"\n",
        "        self.pool_size = pool_size\n",
        "        self.pool_type = pool_type\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        \"\"\"\n",
        "        Perform forward pass for pooling layer.\n",
        "\n",
        "        :param input_data: Input data (batch_size, height, width, channels).\n",
        "        :return: Output data after pooling.\n",
        "        \"\"\"\n",
        "        batch_size, height, width, channels = input_data.shape\n",
        "        pool_height, pool_width = self.pool_size\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        out_height = height // pool_height\n",
        "        out_width = width // pool_width\n",
        "\n",
        "        # Initialize output array\n",
        "        output_data = np.zeros((batch_size, out_height, out_width, channels))\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            for h in range(out_height):\n",
        "                for w in range(out_width):\n",
        "                    for c in range(channels):\n",
        "                        h_start = h * pool_height\n",
        "                        h_end = h_start + pool_height\n",
        "                        w_start = w * pool_width\n",
        "                        w_end = w_start + pool_width\n",
        "\n",
        "                        # Extract a patch from the input data\n",
        "                        patch = input_data[b, h_start:h_end, w_start:w_end, c]\n",
        "\n",
        "                        # Perform pooling\n",
        "                        if self.pool_type == 'MAX':\n",
        "                            output_data[b, h, w, c] = np.max(patch)\n",
        "                        elif self.pool_type == 'AVG':\n",
        "                            output_data[b, h, w, c] = np.mean(patch)\n",
        "\n",
        "        return output_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRFjGV06UzcU"
      },
      "source": [
        "# Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BFz-NGW7U1YL"
      },
      "outputs": [],
      "source": [
        "def activation_function(Z):\n",
        "    \"\"\"\n",
        "    Simple activation function A(Z) = Z if Z >= 0, else A(Z) = 0.\n",
        "\n",
        "    :param Z: Input data.\n",
        "    :return: Activated output.\n",
        "    \"\"\"\n",
        "    return np.maximum(0, Z)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnu4ADfaZ8GQ"
      },
      "source": [
        "# Conv Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iMq9Y6MyaBmV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the Convolution block\n",
        "class ConvBlock:\n",
        "    def __init__(self, num_filters, filter_size=(3, 3, 3), pool_size=(2, 2)):\n",
        "        \"\"\"\n",
        "        Initialize the ConvBlock.\n",
        "\n",
        "        :param num_filters: Number of filters.\n",
        "        :param filter_size: Size of the filters (height, width, channels). Default is (3, 3, 3).\n",
        "        :param pool_size: Size of the pooling filter (height, width). Default is (2, 2).\n",
        "        \"\"\"\n",
        "        self.conv_layer = ConvLayer(num_filters, filter_size)\n",
        "        self.pool_layer = PoolingLayer(pool_size)\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        \"\"\"\n",
        "        Perform forward pass for the ConvBlock.\n",
        "\n",
        "        :param input_data: Input data (batch_size, height, width, channels).\n",
        "        :return: Output data after convolution and pooling.\n",
        "        \"\"\"\n",
        "        conv_output = self.conv_layer.forward(input_data)\n",
        "        pool_output = self.pool_layer.forward(conv_output)\n",
        "        return pool_output\n",
        "\n",
        "\n",
        "# Define the Flattening layer\n",
        "class FlattenLayer:\n",
        "    def forward(self, input_data):\n",
        "        \"\"\"\n",
        "        Flatten the input data.\n",
        "\n",
        "        :param input_data: Input data (batch_size, height, width, channels).\n",
        "        :return: Flattened data.\n",
        "        \"\"\"\n",
        "        batch_size = input_data.shape[0]\n",
        "        return input_data.reshape(batch_size, -1)\n",
        "\n",
        "\n",
        "# Create the network\n",
        "class SimpleCNN:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the SimpleCNN network.\n",
        "        \"\"\"\n",
        "        self.conv_block1 = ConvBlock(5)  # Filter size is (3, 3, 3)\n",
        "        self.conv_block2 = ConvBlock(5)  # Filter size is (3, 3, 3)\n",
        "        self.conv_block3 = ConvBlock(5)  # Filter size is (3, 3, 3)\n",
        "        self.flatten_layer = FlattenLayer()\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        \"\"\"\n",
        "        Perform forward pass for the SimpleCNN network.\n",
        "\n",
        "        :param input_data: Input data (batch_size, height, width, channels).\n",
        "        :return: Output data after passing through the network.\n",
        "        \"\"\"\n",
        "        # Convolution block 1\n",
        "        conv1_output = self.conv_block1.forward(input_data)\n",
        "\n",
        "        # Convolution block 2\n",
        "        conv2_output = self.conv_block2.forward(conv1_output)\n",
        "\n",
        "        # Convolution block 3\n",
        "        conv3_output = self.conv_block3.forward(conv2_output)\n",
        "\n",
        "        # Flatten\n",
        "        flattened_output = self.flatten_layer.forward(conv3_output)\n",
        "\n",
        "        # Downsampling to size 1x128 \n",
        "        downsampled_output = flattened_output[:, :128]\n",
        "\n",
        "        return downsampled_output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdJRg7K0icMD",
        "outputId": "102cb39a-5d5f-40c8-937d-25afffde6b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images and labels saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "folder_path1 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Our Dataset\\Our Dataset\\Karim Abdelaziz Cropped 2\\KarimTraining'\n",
        "folder_path2 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Our Dataset\\Our Dataset\\Hend Sabry Cropped\\HendTraining'\n",
        "folder_path3 = r'G:\\Deep Learning in Computer Vision (DMET1067)\\Milestone 2\\Our Dataset\\Our Dataset\\Hany Ramzy Cropped\\HanyTraining'\n",
        "\n",
        "# Function to read images and resize them\n",
        "def read_images_from_folder(folder_path, label, image_size=(512, 512)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, image_size)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Paths to your image folders and labels\n",
        "folder_paths = [folder_path1, folder_path2, folder_path3]\n",
        "labels = [\"Karim\", \"Hend\", \"Hany\"]  \n",
        "\n",
        "# Initialize empty lists to store images and corresponding labels\n",
        "test_images = []\n",
        "test_true_labels = []\n",
        "\n",
        "# Read images from each folder and store them in all_images list\n",
        "for folder_path, label in zip(folder_paths, labels):\n",
        "    images, label_list = read_images_from_folder(folder_path, label)\n",
        "    test_images.extend(images)\n",
        "    test_true_labels.extend(label_list)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "test_images = np.array(test_images)\n",
        "test_true_labels = np.array(test_true_labels)\n",
        "\n",
        "# Save the images and labels arrays to numpy files\n",
        "np.save(\"test_images.npy\", test_images)\n",
        "np.save(\"test_true_labels.npy\", test_true_labels)\n",
        "\n",
        "print(\"Images and labels saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd1FCaiqiyhZ",
        "outputId": "cb0832d2-540e-459a-91de-37b2f6f940e0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Load the test images and true labels\n",
        "test_images = np.load(\"test_images.npy\")\n",
        "test_true_labels = np.load(\"test_true_labels.npy\")\n",
        "\n",
        "\n",
        "# Initialize the SimpleCNN network\n",
        "simple_cnn = SimpleCNN()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Forward pass through the CNN to get features\n",
        "def extract_features(model, images, true_labels):\n",
        "    features = []\n",
        "    labeled_features = []  \n",
        "    \n",
        "    for image, label in zip(images, true_labels):\n",
        "        output = model.forward(image[np.newaxis, :, :, :])\n",
        "        flattened_output = output.flatten()\n",
        "        \n",
        "        features.append(flattened_output)\n",
        "        labeled_features.append((flattened_output, label))\n",
        "        \n",
        "    return np.array(features), labeled_features\n",
        "\n",
        "# Extract features and labeled features from test images\n",
        "features, labeled_features = extract_features(simple_cnn, test_images, test_true_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "kmeans = KMeans(n_clusters=num_classes)\n",
        "kmeans.fit(features)\n",
        "\n",
        "\n",
        "# Get the labels (clusters) assigned by k-means\n",
        "predicted_labels = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "\n",
        "\n",
        "# Create a dictionary to store cluster information\n",
        "cluster_info = defaultdict(list)\n",
        "\n",
        "# Populate cluster_info with original labels for each cluster\n",
        "for i, cluster_label in enumerate(predicted_labels):\n",
        "    original_label = labeled_features[i][1]  \n",
        "    cluster_info[cluster_label].append(original_label)\n",
        "\n",
        "# Count the number of features mapped to each label within each cluster\n",
        "label_distribution_in_clusters = defaultdict(lambda: defaultdict(int))\n",
        "for cluster_label, labels in cluster_info.items():\n",
        "    total_features = len(labels)\n",
        "    label_count = Counter(labels)\n",
        "    label_distribution_in_clusters[cluster_label] = {label: count for label, count in label_count.items()}\n",
        "    label_distribution_in_clusters[cluster_label]['total_features'] = total_features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 44.53%\n"
          ]
        }
      ],
      "source": [
        "# Create a mapping dictionary to map cluster labels to actor names\n",
        "unique_labels = np.unique(test_true_labels)\n",
        "label_map = {i: actor_name for i, actor_name in enumerate(unique_labels)}\n",
        "\n",
        "# Map cluster labels to actor names for predicted labels\n",
        "predicted_actor_names = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_true_labels, predicted_actor_names)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
